{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c966b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03ff527",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=fitz.open(r\"C:\\Users\\Dell\\Desktop\\Panda\\04184 Manual of blood transfusion policy & procedures 6.6.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0841dcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \n",
      "Author: user\n",
      "Creation Date: D:20210707163446+01'00'\n",
      "Modification Date: D:20210707163446+01'00'\n"
     ]
    }
   ],
   "source": [
    "metadata_dict = doc.metadata\n",
    "title = metadata_dict.get(\"title\", \"No title\")\n",
    "author = metadata_dict.get(\"author\", \"No author\")\n",
    "creation_date = metadata_dict.get(\"creationDate\", \"No creation date\")\n",
    "modification_date = metadata_dict.get(\"modDate\", \"No modification date\")\n",
    "\n",
    "print(\"Title:\", title)\n",
    "print(\"Author:\", author)\n",
    "print(\"Creation Date:\", creation_date)\n",
    "print(\"Modification Date:\", modification_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a2420c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format': 'PDF 1.5', 'title': '', 'author': 'user', 'subject': '', 'keywords': '', 'creator': 'Microsoft® Word 2010', 'producer': 'Microsoft® Word 2010', 'creationDate': \"D:20210707163446+01'00'\", 'modDate': \"D:20210707163446+01'00'\", 'trapped': '', 'encryption': None}\n"
     ]
    }
   ],
   "source": [
    "data=doc.metadata\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb41a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1996cd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDell\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPanda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 86\u001b[0m process_pdfs_and_create_csv(input_folder, output_csv)\n",
      "Cell \u001b[1;32mIn[23], line 79\u001b[0m, in \u001b[0;36mprocess_pdfs_and_create_csv\u001b[1;34m(input_folder, output_csv)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf_file \u001b[38;5;129;01min\u001b[39;00m pdf_files:\n\u001b[0;32m     78\u001b[0m     pdf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, pdf_file)\n\u001b[1;32m---> 79\u001b[0m     info \u001b[38;5;241m=\u001b[39m extract_info_from_pdf(pdf_path)\n\u001b[0;32m     80\u001b[0m     csv_writer\u001b[38;5;241m.\u001b[39mwriterow(info)\n",
      "Cell \u001b[1;32mIn[23], line 40\u001b[0m, in \u001b[0;36mextract_info_from_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match_title:\n\u001b[0;32m     38\u001b[0m     document_title \u001b[38;5;241m=\u001b[39m match_title\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m match_version \u001b[38;5;241m=\u001b[39m version_pattern\u001b[38;5;241m.\u001b[39msearch(text)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match_version:\n\u001b[0;32m     42\u001b[0m     version_number \u001b[38;5;241m=\u001b[39m match_version\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_info_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = ''\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")\n",
    "\n",
    "    # Initialize variables to store extracted information\n",
    "    document_title = 'nan'\n",
    "    version_number = 'nan'\n",
    "    reference_number = 'nan'\n",
    "    document_type = 'nan'\n",
    "    issue_date = 'nan'\n",
    "    review_date = 'nan'\n",
    "    author = 'nan'\n",
    "\n",
    "    # Regular expressions to match patterns and extract information\n",
    "    title_pattern = re.compile(r'Document\\s+Title:\\s*(.+)',re.IGNORECASE)\n",
    "    #version_pattern = re.compile(r'Version\\s+Number:\\s*(.+)',re.IGNORECASE)\n",
    "    #version_pattern = re.compile(r'Version:\\s*([\\d.]+)', re.IGNORECASE)\n",
    "    version_pattern = \n",
    "        re.compile(r'Version\\s+Number:\\s*(.+)', re.IGNORECASE),\n",
    "        re.compile(r'Version:\\s*([\\d.]+)', re.IGNORECASE)\n",
    "    \n",
    "    reference_pattern = re.compile(r\"Reference/Register No:\\s*(.*)\",re.IGNORECASE)\n",
    "    type_pattern = re.compile(r'Document\\s+Type:\\s*(.+)',re.IGNORECASE)\n",
    "    issue_pattern = re.compile(r'Issue\\s+Date:\\s*(.+)',re.IGNORECASE)\n",
    "    review_pattern = re.compile(r'Review\\s+Date:\\s*(.+)',re.IGNORECASE)\n",
    "    author_pattern = re.compile(r'Author:\\s*(.+)',re.IGNORECASE)\n",
    "\n",
    "    # Extract information using regular expressions\n",
    "    match_title = title_pattern.search(text)\n",
    "    if match_title:\n",
    "        document_title = match_title.group(1)\n",
    "\n",
    "    match_version = version_pattern.search(text)\n",
    "    if match_version:\n",
    "        version_number = match_version.group(1)\n",
    "\n",
    "    match_reference = reference_pattern.search(text)\n",
    "    if match_reference:\n",
    "        reference_number = match_reference.group(1)\n",
    "\n",
    "    match_type = type_pattern.search(text)\n",
    "    if match_type:\n",
    "        document_type = match_type.group(1)\n",
    "\n",
    "    match_issue = issue_pattern.search(text)\n",
    "    if match_issue:\n",
    "        issue_date = match_issue.group(1)\n",
    "\n",
    "    match_review = review_pattern.search(text)\n",
    "    if match_review:\n",
    "        review_date = match_review.group(1)\n",
    "\n",
    "    match_author = author_pattern.search(text)\n",
    "    if match_author:\n",
    "        author = match_author.group(1)\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return [document_title, version_number, reference_number, document_type, issue_date, review_date, author]\n",
    "\n",
    "def process_pdfs_and_create_csv(input_folder, output_csv):\n",
    "    pdf_files = [file for file in os.listdir(input_folder) if file.lower().endswith('.pdf')]\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        header = [\"Document Title\", \"Version Number\", \"Reference/Register Number\",\n",
    "                  \"Document Type\", \"Issue Date\", \"Review Date\", \"Author\"]\n",
    "        csv_writer.writerow(header)\n",
    "\n",
    "        for pdf_file in pdf_files:\n",
    "            pdf_path = os.path.join(input_folder, pdf_file)\n",
    "            info = extract_info_from_pdf(pdf_path)\n",
    "            csv_writer.writerow(info)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder =  r\"C:\\Users\\Dell\\Desktop\\Panda\"\n",
    "    output_csv = \"output.csv\"\n",
    "\n",
    "    process_pdfs_and_create_csv(input_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e94dc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'issue_pattern' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m   \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDell\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPanda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput-mu.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m process_pdfs_and_create_csv(input_folder, output_csv)\n",
      "Cell \u001b[1;32mIn[9], line 75\u001b[0m, in \u001b[0;36mprocess_pdfs_and_create_csv\u001b[1;34m(input_folder, output_csv)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf_file \u001b[38;5;129;01min\u001b[39;00m pdf_files:\n\u001b[0;32m     74\u001b[0m     pdf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, pdf_file)\n\u001b[1;32m---> 75\u001b[0m     info \u001b[38;5;241m=\u001b[39m extract_info_from_pdf(pdf_path)\n\u001b[0;32m     76\u001b[0m     csv_writer\u001b[38;5;241m.\u001b[39mwriterow(info)\n",
      "Cell \u001b[1;32mIn[9], line 48\u001b[0m, in \u001b[0;36mextract_info_from_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match_type:\n\u001b[0;32m     46\u001b[0m     document_type \u001b[38;5;241m=\u001b[39m match_type\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m match_issue \u001b[38;5;241m=\u001b[39m issue_pattern\u001b[38;5;241m.\u001b[39msearch(text)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match_issue:\n\u001b[0;32m     50\u001b[0m     issue_date \u001b[38;5;241m=\u001b[39m match_issue\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'issue_pattern' is not defined"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_info_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = ''\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")\n",
    "\n",
    "    document_title = 'nan'\n",
    "    version_number = 'nan'\n",
    "    reference_number = 'nan'\n",
    "    document_type = 'nan'\n",
    "    issue_date = 'nan'\n",
    "    review_date = 'nan'\n",
    "    author = 'nan'\n",
    "\n",
    "    title_pattern = re.compile(r'Document\\s+Title:\\s*(.+)',re.IGNORECASE)\n",
    "    version_patterns = [\n",
    "        re.compile(r'Version\\s+Number:\\s*(.+)',re.IGNORECASE),\n",
    "        re.compile(r'Version:\\s*([\\d.]+)',re.IGNORECASE)\n",
    "    ]\n",
    "    reference_pattern = re.compile(r\"Reference/Register No:\\s*(.*)\",re.IGNORECASE)\n",
    "    type_pattern = re.compile(r'Document\\s+Type:\\s*(.+)',re.IGNORECASE)\n",
    "    review_pattern = re.compile(r'Review\\s+Date:\\s*(.+)',re.IGNORECASE)\n",
    "    author_pattern = re.compile(r'Author:\\s*(.+)',re.IGNORECASE)\n",
    "\n",
    "    match_title = title_pattern.search(text)\n",
    "    if match_title:\n",
    "        document_title = match_title.group(1)\n",
    "\n",
    "    for pattern in version_patterns:\n",
    "        match_version = pattern.search(text)\n",
    "        if match_version:\n",
    "            version_number = match_version.group(1)\n",
    "            break\n",
    "\n",
    "    match_reference = reference_pattern.search(text)\n",
    "    if match_reference:\n",
    "        reference_number = match_reference.group(1)\n",
    "\n",
    "    match_type = type_pattern.search(text)\n",
    "    if match_type:\n",
    "        document_type = match_type.group(1)\n",
    "\n",
    "    match_issue = issue_pattern.search(text)\n",
    "    if match_issue:\n",
    "        issue_date = match_issue.group(1)\n",
    "\n",
    "    match_review = review_pattern.search(text)\n",
    "    if match_review:\n",
    "        review_date = match_review.group(1)\n",
    "\n",
    "    match_author = author_pattern.search(text)\n",
    "    if match_author:\n",
    "        author = match_author.group(1)\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return [document_title, version_number, reference_number, document_type, issue_date, review_date, author]\n",
    "\n",
    "def process_pdfs_and_create_csv(input_folder, output_csv):\n",
    "    pdf_files = [file for file in os.listdir(input_folder) if file.lower().endswith('.pdf')]\n",
    "\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        header = [\"Document Title\", \"Version Number\", \"Reference/Register Number\",\n",
    "                  \"Document Type\", \"Issue Date\", \"Review Date\", \"Author\"]\n",
    "        csv_writer.writerow(header)\n",
    "\n",
    "        for pdf_file in pdf_files:\n",
    "            pdf_path = os.path.join(input_folder, pdf_file)\n",
    "            info = extract_info_from_pdf(pdf_path)\n",
    "            csv_writer.writerow(info)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder =   r\"C:\\Users\\Dell\\Desktop\\Panda\"\n",
    "    output_csv = \"output-mu.csv\"\n",
    "\n",
    "    process_pdfs_and_create_csv(input_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544209b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "import os\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab5abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2589ec7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 're.Pattern'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m   \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDell\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPanda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m new_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf_data_extraction.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 106\u001b[0m data_processing(input_folder,new_file)\n",
      "Cell \u001b[1;32mIn[5], line 99\u001b[0m, in \u001b[0;36mdata_processing\u001b[1;34m(input_folder, new_file)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf_file \u001b[38;5;129;01min\u001b[39;00m  all_files:\n\u001b[0;32m     98\u001b[0m     pdf_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder,pdf_file)\n\u001b[1;32m---> 99\u001b[0m     info\u001b[38;5;241m=\u001b[39mdata_info_extraction(pdf_path)\n\u001b[0;32m    100\u001b[0m     csv_write\u001b[38;5;241m.\u001b[39mwriterow(info)\n",
      "Cell \u001b[1;32mIn[5], line 70\u001b[0m, in \u001b[0;36mdata_info_extraction\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m    \n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m issue \u001b[38;5;129;01min\u001b[39;00m issue_patterns:\n\u001b[1;32m---> 70\u001b[0m     match_issue\u001b[38;5;241m=\u001b[39missue\u001b[38;5;241m.\u001b[39msearch(title)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match_issue:\n\u001b[0;32m     72\u001b[0m         issue_date\u001b[38;5;241m=\u001b[39mmatch_issue\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object, got 're.Pattern'"
     ]
    }
   ],
   "source": [
    "def data_info_extraction(pdf_path):\n",
    "    doc=fitz.open(pdf_path)\n",
    "    text=''\n",
    "    for page in doc:\n",
    "        text+=page.get_text(\"text\")\n",
    "    document_title = 'nan'\n",
    "    version_number = 'nan'\n",
    "    reference_number = 'nan'\n",
    "    document_type = 'nan'\n",
    "    issue_date = 'nan'\n",
    "    review_date = 'nan'\n",
    "    author = 'nan'\n",
    "    \n",
    "    title_patterns=[\n",
    "        re.compile(r\"Document\\s+title:\\s*(.*)\",re.IGNORECASE),\n",
    "        re.compile(r\"Title:\\s*(.*)\",re.IGNORECASE)\n",
    "\n",
    "        \n",
    "    ]\n",
    "    version_patterns = [\n",
    "        re.compile(r'Version\\s+Number:\\s*(.+)',re.IGNORECASE),\n",
    "        re.compile(r'Version:\\s*([\\d.]+)',re.IGNORECASE)\n",
    "    ]\n",
    "    reference_patterns = [\n",
    "        re.compile(r\"Reference/Register No:\\s*(.*)\",re.IGNORECASE),\n",
    "        re.compile(r\"Ref:\\s*(.*)\",re.IGNORECASE)\n",
    "    ]\n",
    "    type_patterns =[\n",
    "    re.compile(r'Document\\s+Type:\\s*(.+)',re.IGNORECASE),\n",
    "    re.compile(r'Category:\\s*(.+)',re.IGNORECASE)\n",
    "\n",
    "    ]\n",
    "    issue_patterns =[\n",
    "    re.compile(r'Issue\\s+Date:\\s*(.+)',re.IGNORECASE),\n",
    "    re.compile(r'Date approved\\s*(.+)',re.IGNORECASE)\n",
    "\n",
    "    ]\n",
    "    review_patterns =[\n",
    "    re.compile(r'Review\\s+Date:\\s*(.+)',re.IGNORECASE),\n",
    "    re.compile(r'Review\\s+Date\\s*(.+)',re.IGNORECASE)\n",
    "\n",
    "    ]\n",
    "    author_patterns =[\n",
    "    re.compile(r'Author:\\s*(.+)',re.IGNORECASE)\n",
    "    ]\n",
    "    \n",
    "    for title in title_patterns:\n",
    "        match_title=title.search(text)\n",
    "        if match_title:\n",
    "            document_title=match_title.group(1)\n",
    "            break           \n",
    "     \n",
    "    for version in version_patterns:\n",
    "        match_version=version.search(text)\n",
    "        if match_version:\n",
    "            version_number=match_version.group(1)\n",
    "            break  \n",
    "    \n",
    "    for reference in reference_patterns:\n",
    "        match_reference=reference.search(text)\n",
    "        if match_reference:\n",
    "            reference_number=match_reference.group(1)\n",
    "            break \n",
    "    for dtype in type_patterns:\n",
    "        match_dtype=dtype.search(text)\n",
    "        if match_dtype:\n",
    "            document_type=match_dtype.group(1)\n",
    "            break    \n",
    "    for issue in issue_patterns:\n",
    "        match_issue=issue.search(title)\n",
    "        if match_issue:\n",
    "            issue_date=match_issue.group(1)\n",
    "            break  \n",
    "    \n",
    "    for review in review_patterns:\n",
    "        match_review=review.search(title)\n",
    "        if match_review:\n",
    "            review_date=match_review.group(1)\n",
    "            break \n",
    "    for dauthor in author_patterns:\n",
    "        match_dauthor=dauthor.search(title)\n",
    "        if match_dauthor:\n",
    "            author=match_dauthor.group(1)\n",
    "            break \n",
    "        \n",
    "    return [document_title, version_number, reference_number, document_type, issue_date, review_date, author]\n",
    "       \n",
    "def data_processing(input_folder,new_file):\n",
    "    \n",
    "    all_files=[file for file in os.listdir(input_folder)  if file.lower().endswith('.pdf')]\n",
    "    with open(new_file,\"w\",newline=\"\",encoding=\"utf-8\") as f:\n",
    "        csv_write=csv.writer(f)\n",
    "        header = [\"Document Title\", \"Version Number\", \"Reference/Register Number\",\n",
    "                  \"Document Type\", \"Issue Date\", \"Review Date\", \"Author\"]\n",
    "        csv_write.writerow(header)\n",
    "    \n",
    "        for pdf_file in  all_files:\n",
    "            pdf_path=os.path.join(input_folder,pdf_file)\n",
    "            info=data_info_extraction(pdf_path)\n",
    "            csv_write.writerow(info)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    input_folder =   r\"C:\\Users\\Dell\\Desktop\\Panda\"\n",
    "    new_file=\"pdf_data_extraction.csv\"\n",
    "    data_processing(input_folder,new_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
